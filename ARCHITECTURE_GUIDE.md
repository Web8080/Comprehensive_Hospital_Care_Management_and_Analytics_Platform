# Architecture Guide: When Do You Need Snowflake?

**Author:** Victor Ibhafidon

## TL;DR

- **For local testing/demos:** NO Snowflake needed (use DuckDB)
- **For Matillion:** YES Snowflake required (Matillion transforms data IN Snowflake)
- **queries.py:** Used in BOTH scenarios (queries work on DuckDB or Snowflake)

---

## Two Deployment Architectures

### Architecture 1: Local Development (No Cloud Required)

```
[CSV Files] → [Python Script] → [DuckDB] → [Streamlit Dashboard]
   (data/raw)  (01_generate_data.py)  (Local file)  (queries.py)
```

**Components:**
- **Data Source:** CSV files generated by Python
- **Database:** DuckDB (embedded, no server needed)
- **ETL:** Python scripts load CSVs into DuckDB
- **Dashboard:** Streamlit queries DuckDB using queries.py
- **Cost:** $0
- **Setup:** 3 commands (see QUICK_START.md)

**When to use:**
- Development and testing
- Portfolio demos
- Learning the system
- No internet required (fully offline)

---

### Architecture 2: Production with Matillion (Cloud Required)

```
                    ┌─────────────────────────────────────┐
                    │        SNOWFLAKE WAREHOUSE          │
                    │                                     │
[CSV Files] ────────┼──▶ [BRONZE] ──▶ [SILVER] ──▶ [GOLD]│
Upload via UI       │      Raw        Cleaned    Analytics│
or SnowSQL         │                                     │
                    └──────┬──────────────────────▲──────┘
                           │                      │
                           ▼                      │
                    ┌──────────────┐              │
                    │  MATILLION   │              │
                    │  ETL JOBS    │──────────────┘
                    │              │  Transforms data
                    │ - Cleaning   │  IN Snowflake
                    │ - Validation │  (ELT approach)
                    │ - Star Schema│
                    └──────────────┘
                           │
                           │ Streamlit connects
                           │ to Snowflake GOLD
                           ▼
                    [Streamlit Dashboard]
                    Uses queries.py to
                    query Snowflake
```

**Components:**
- **Data Source:** CSV files uploaded to Snowflake
- **Database:** Snowflake (cloud data warehouse)
- **ETL:** Matillion ETL (visual workflow tool)
- **Dashboard:** Streamlit queries Snowflake using queries.py
- **Cost:** ~$50-200/month (consumption-based)
- **Setup:** 2-3 hours (see SETUP_INSTRUCTIONS.md)

**When to use:**
- Production deployment
- Learning Matillion (for resume/portfolio)
- Scaling to 10K+ patients
- Enterprise showcase

---

## Why Matillion Requires Snowflake

**Common Misconception:** "Matillion is an ETL tool, so it processes data independently"

**Reality:** Matillion is an **orchestration tool** that transforms data INSIDE your data warehouse.

**Matillion Architecture:**
1. You connect Matillion to Snowflake (or BigQuery, Redshift)
2. Matillion sends SQL to Snowflake
3. Snowflake executes the transformations
4. Matillion monitors and schedules the jobs

**Matillion does NOT:**
- Store data itself
- Run on your laptop
- Work without a cloud data warehouse

**Matillion DOES:**
- Create visual ETL workflows
- Generate optimized SQL
- Schedule automated runs
- Monitor job performance

---

## What Does queries.py Do?

**queries.py** contains SQL queries used by Streamlit dashboards to fetch data.

**Works with BOTH:**
- **DuckDB:** Local database queries
- **Snowflake:** Cloud database queries

**Example query from queries.py:**
```sql
QUERY_CURRENT_OCCUPANCY = """
SELECT 
    COUNT(DISTINCT a.patient_id) as current_patients,
    (SELECT SUM(bed_capacity) FROM dim_wards) as total_beds
FROM fact_admissions a
WHERE a.discharge_date >= CURRENT_DATE
"""
```

This SQL works identically on DuckDB and Snowflake because both support standard SQL.

**Why queries.py is important:**
- Centralizes all analytical queries (30+ queries)
- Avoids SQL duplication in dashboard code
- Makes query optimization easier
- Works across both architectures

---

## Step-by-Step: Using Matillion with Snowflake

### Step 1: Generate Data Locally

```bash
python scripts/01_generate_data.py
```

Output: 15 CSV files in `data/raw/`

### Step 2: Sign Up for Snowflake

1. Go to https://signup.snowflake.com
2. Choose: Standard Edition, AWS, US East
3. Save your account URL, username, password

### Step 3: Upload CSVs to Snowflake

**Option A: Web UI (Easiest)**
1. Log into Snowflake
2. Create database: `CREATE DATABASE MEDICARE_ANALYTICS;`
3. Create schema: `CREATE SCHEMA BRONZE;`
4. Click "Load Data" → Upload CSVs
5. Repeat for all 15 files

**Option B: SnowSQL (Command Line)**
```bash
snowsql -a <your_account> -u <username>
PUT file://data/raw/*.csv @MEDICARE_ANALYTICS.BRONZE.%stage;
```

### Step 4: Sign Up for Matillion

1. Go to https://www.matillion.com/try-now/
2. Select "Matillion ETL for Snowflake"
3. Connect to your Snowflake account

### Step 5: Create Matillion Jobs

Use SQL from `sql/matillion_transformations.sql`:

**Job 1: Bronze → Silver**
```sql
CREATE TABLE SILVER.cleaned_admissions AS
SELECT
    CAST(admission_id AS INTEGER),
    CAST(admission_date AS DATE),
    -- cleaning logic
FROM BRONZE.raw_admissions;
```

**Job 2: Silver → Gold**
```sql
CREATE TABLE GOLD.fact_admissions AS
SELECT * FROM SILVER.cleaned_admissions;
```

### Step 6: Update Streamlit to Use Snowflake

Create `.env` file:
```
DATABASE_TYPE=snowflake
SNOWFLAKE_ACCOUNT=abc12345.us-east-1
SNOWFLAKE_USER=your_username
SNOWFLAKE_PASSWORD=your_password
SNOWFLAKE_DATABASE=MEDICARE_ANALYTICS
SNOWFLAKE_WAREHOUSE=ANALYTICS_WH
SNOWFLAKE_SCHEMA=GOLD
```

### Step 7: Run Dashboard

```bash
streamlit run streamlit_app/app.py
```

Now Streamlit queries Snowflake (not DuckDB).

---

## Quick Reference

| Question | Answer |
|----------|--------|
| Can I run this without Snowflake? | YES - use DuckDB for local testing |
| Can I use Matillion without Snowflake? | NO - Matillion requires a cloud warehouse |
| Is queries.py empty? | NO - it has 372 lines of SQL (30+ queries) |
| Does Matillion store data? | NO - it transforms data IN Snowflake |
| Can I deploy dashboards for free? | YES - Streamlit Cloud is free |
| Do I need Matillion for production? | NO - you can use Python/dbt instead |
| What does Matillion cost? | ~$2,000/month (14-day free trial) |
| What does Snowflake cost? | ~$50-200/month (30-day $400 credit) |

---

## Decision Tree

```
Start
 │
 ├─ Are you learning/testing? ──▶ Use DuckDB (free, local)
 │
 ├─ Do you want Matillion experience? ──▶ Use Snowflake + Matillion
 │                                         (great for resume)
 │
 ├─ Do you need enterprise deployment? ──▶ Use Snowflake + Matillion
 │                                          (production-ready)
 │
 └─ Do you want free production? ──▶ Use Snowflake free tier + Python ETL
                                     (no Matillion, still enterprise-grade)
```

---

## File Locations

**Queries (372 lines of SQL):**
- `streamlit_app/utils/queries.py` - Dashboard queries

**Matillion Transformation SQL:**
- `sql/matillion_transformations.sql` - Copy-paste into Matillion jobs

**Database Schema:**
- `sql/schema/gold_schema.sql` - Star schema DDL

**Python ETL (alternative to Matillion):**
- Could be added to `scripts/02_etl_bronze_to_silver.py`
- Not included because Matillion is the focus

---

## Summary

**For Portfolio/Learning:**
- Run locally with DuckDB (no Snowflake)
- Show you can build dashboards
- Mention "designed for Snowflake + Matillion"

**For Matillion Experience:**
- Use Snowflake 30-day trial ($400 credits)
- Use Matillion 14-day trial
- Upload data, create 2-3 ETL jobs
- Deploy dashboards querying Snowflake

**Key Insight:**
Matillion is NOT a standalone ETL tool. It's an orchestration layer that generates and runs SQL in your data warehouse (Snowflake/BigQuery/Redshift). You cannot use Matillion without a cloud data warehouse.

---

**Questions?** See SETUP_INSTRUCTIONS.md for detailed Snowflake + Matillion setup.

